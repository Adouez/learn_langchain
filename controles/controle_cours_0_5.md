# üìù CONTR√îLE DE CONNAISSANCES - LangChain (Le√ßons 0 √† 5)

**üìÖ Date du contr√¥le** : 12 janvier 2026  
**üë§ Candidat** : Antoine

---

## üìã Informations

| | |
|---|---|
| **Cours couverts** | Introduction, Fondations, Prompt Templates, Chains/LCEL, Memory, RAG |
| **Nombre de questions** | 15 |
| **Score final** | **10/15 (67%)** |
| **Notation** | ‚úÖ Acquis / üîÑ √Ä revoir / ‚ùå Non acquis |

---

# üöÄ PARTIE 1 : La M√©taphore (Le√ßon 0)

### Question 1 - Compr√©hension
Dans la m√©taphore de la voiture, √† quoi correspond chaque √©l√©ment ?

| √âl√©ment | R√©ponse d'Antoine | Correction | Verdict |
|---------|-------------------|------------|---------|
| **Le moteur** | LLM (GPT-4) | LLM | ‚úÖ |
| **Le ch√¢ssis** | L'appel API | **LangChain** (le framework) | ‚ùå |
| **Le syst√®me de transmission** | Le prompting | **Les Chains** (encha√Ænement avec `\|`) | üîÑ |
| **Le GPS avec historique** | La m√©moire | Memory | ‚úÖ |
| **Le coffre √† bagages** | Les documents | RAG | ‚úÖ |

**Score Q1** : üîÑ √Ä revoir (3/5)

---

# üîå PARTIE 2 : Les Fondations (Le√ßon 1)

### Question 2 - D√©finition
**Q : Qu'est-ce qu'un LLM ? Donne un exemple.**

> **R√©ponse d'Antoine** : "C'est un mod√®le IA sp√©cialis√© dans la conversation avec un humain. Les mod√®les les plus connus sont ChatGPT, Gemini, Claude Opus, DeepSeek"

‚úÖ **Acquis** ‚Äî Bonne r√©ponse ! Pr√©cision : LLM = Large Language Model, capable de comprendre ET g√©n√©rer du langage naturel (pas uniquement conversation).

---

### Question 3 - S√©curit√©
**Q : Pourquoi ne faut-il jamais mettre sa cl√© API directement dans le code ? Quelle est la bonne pratique ?**

> **R√©ponse d'Antoine** : "Il faut mettre la cl√© API dans un .env ou tout autre fichier √©num√©r√© dans .gitignore"

‚úÖ **Acquis** ‚Äî Bonne pratique identifi√©e ! Le "pourquoi" implicite : √©viter l'exposition publique de la cl√© (factures, abus).

---

### Question 4 - Code
**Q : Quelle m√©thode utilise-t-on pour envoyer un message au mod√®le et recevoir une r√©ponse ?**

> **R√©ponse d'Antoine** : "invoke"

‚úÖ **Acquis** ‚Äî Parfait ! `llm.invoke("message")`

---

**Score Partie 2** : ‚úÖ **3/3**

---

# üß© PARTIE 3 : Prompt Templates (Le√ßon 2)

### Question 5 - Compr√©hension
**Q : Explique la diff√©rence entre un System Message et un Human Message. √Ä quoi sert chacun ?**

> **R√©ponse d'Antoine** : "Le prompt system donne une direction au LLM, comment il doit se comporter. Le prompt humain c'est ce que l'humain demande et √† quoi doit r√©pondre le LLM en se comportant comme le prompt system l'a d√©fini"

‚úÖ **Acquis** ‚Äî Excellente compr√©hension de la relation entre les deux !

---

### Question 6 - Avantages
**Q : Cite 2 avantages d'utiliser des Prompt Templates plut√¥t que d'√©crire les prompts "en dur".**

> **R√©ponse d'Antoine** : "C'est pour avoir une meilleure m√©moire du LLM et √ßa stabilise le comportement global du LLM, r√©duisant les hallucinations ?"

‚ùå **Non acquis** ‚Äî Confusion avec d'autres concepts.

**Les vraies r√©ponses** :
1. **R√©utilisabilit√©** : Un "moule" qu'on r√©utilise en changeant les variables
2. **Contextualisation** : D√©finir un r√¥le coh√©rent appliqu√© √† chaque requ√™te

---

### Question 7 - Syntaxe
**Q : Dans un Prompt Template, √† quoi servent les `{accolades}` ?**

> **R√©ponse d'Antoine** : "C'est l'emplacement dans le prompt template de ce que va demander l'utilisateur humain"

‚úÖ **Acquis** ‚Äî Bonne id√©e ! Ce sont des **variables/placeholders** remplac√©es dynamiquement (pas seulement pour la question utilisateur : `{contexte}`, `{langue}`, etc.)

---

**Score Partie 3** : üîÑ **2/3**

---

# üîó PARTIE 4 : Chains et LCEL (Le√ßon 3)

### Question 8 - D√©finition
**Q : Que signifie LCEL ? √Ä quoi √ßa sert ?**

> **R√©ponse d'Antoine** : "Je ne sais pas"

‚ùå **Non acquis**

**La r√©ponse** : **LCEL = LangChain Expression Language**
- Syntaxe avec le pipe `|` pour encha√Æner les composants
- `chain = prompt | llm | parser`

---

### Question 9 - Compr√©hension
**Q : Dans cette cha√Æne, explique le r√¥le de chaque composant :**
```python
chain = prompt | llm | StrOutputParser()
```

> **R√©ponse d'Antoine** : "Le prompt c'est l'ensemble des √©l√©ments (questions, variables, system) que l'on donne au LLM, le LLM c'est le mod√®le que l'on choisit pour r√©pondre et le parser c'est la d√©composition des √©l√©ments pour qu'ils soient divis√©s pour √™tre ing√©r√©s correctement, par token, par le mod√®le LLM"

üîÑ **√Ä revoir** (2/3 correct)

| Composant | R√©ponse | Verdict |
|-----------|---------|---------|
| prompt | ‚úÖ Correct | ‚úÖ |
| llm | ‚úÖ Correct | ‚úÖ |
| StrOutputParser | ‚ùå Confusion avec tokenisation | ‚ùå |

**Correction** : Le Parser nettoie la **SORTIE** du LLM (transforme `AIMessage` en string), pas l'entr√©e !

---

### Question 10 - Flux de donn√©es
**Q : D√©cris ce qui se passe √©tape par √©tape quand on ex√©cute :**
```python
chain.invoke({"question": "C'est quoi Python ?"})
```

> **R√©ponse d'Antoine** : "D'abord le prompt est envoy√© au LLM, ensuite le LLM r√©pond et √† la fin de la cha√Æne, le parser nettoie la r√©ponse"

‚úÖ **Acquis** ‚Äî Flux correct et correction sur le Parser retenue !

---

**Score Partie 4** : ‚ùå **1/3**

---

# üß† PARTIE 5 : La M√©moire (Le√ßon 4)

### Question 11 - Probl√®me
**Q : Explique pourquoi un LLM est dit "stateless" par d√©faut. Quel probl√®me cela pose pour un chatbot ?**

> **R√©ponse d'Antoine** : "Par d√©faut le LLM ne retient pas ce qui a √©t√© dit, il est 'reset' √† chaque prompt. C'est un probl√®me car si je lui dis que je m'appelle Antoine, qu'ensuite je lui demande comment je m'appelle et qu'il ne sait plus, la conversation n'aura aucun sens"

‚úÖ **Acquis** ‚Äî Excellente explication avec exemple concret !

---

### Question 12 - Composants
**Q : √Ä quoi sert le `MessagesPlaceholder` dans un Prompt Template ?**

> **R√©ponse d'Antoine** : "Il vient ajouter √† chaque question les questions et r√©ponses pr√©c√©dentes entre le LLM et l'utilisateur"

‚úÖ **Acquis** ‚Äî Parfait ! C'est la "case vide" pour injecter l'historique.

---

### Question 13 - Utilit√©
**Q : Pourquoi utilise-t-on un `session_id` ? Donne un exemple concret.**

> **R√©ponse d'Antoine** : "C'est pour 'enregistrer' un historique, √ßa permet de revenir dessus. Si j'ai une discussion au sujet d'une recette de mayonnaise et qu'ensuite je veux une recette d'≈ìuf mimosa, je peux reprendre le session_id de ma mayonnaise pour faire mon ≈ìuf mimosa"

‚úÖ **Acquis** ‚Äî Bon exemple ! Permet aussi de s√©parer les utilisateurs (Alice vs Bob).

---

**Score Partie 5** : ‚úÖ **3/3** üéâ

---

# üìö PARTIE 6 : RAG (Le√ßon 5)

### Question 14 - D√©finition
**Q : Que signifie RAG et √† quoi √ßa sert ?**

> **R√©ponse d'Antoine** : "Je n'ai pas la signification de RAG mais √ßa permet d'ajouter du contenu 'perso' aux connaissances du LLM, des documents priv√©s etc..."

üîÑ **√Ä revoir** ‚Äî Utilit√© comprise, acronyme manquant.

**La r√©ponse** : **RAG = Retrieval Augmented Generation** (G√©n√©ration Augment√©e par R√©cup√©ration)

---

### Question 15 - Processus
**Q : Remets dans l'ordre les √©tapes du RAG :**

| √âtape | R√©ponse d'Antoine | Correct | Verdict |
|-------|-------------------|---------|---------|
| Charger le document | 1 | 1 | ‚úÖ |
| D√©couper en chunks | 2 | 2 | ‚úÖ |
| Stocker dans une base vectorielle | 3 | **4** | ‚ùå |
| Transformer en vecteurs (embeddings) | 4 | **3** | ‚ùå |
| Chercher les morceaux pertinents | 5 | 5 | ‚úÖ |
| G√©n√©rer une r√©ponse avec le contexte | 6 | 6 | ‚úÖ |

üîÑ **√Ä revoir** (4/6) ‚Äî Inversion : on vectorise AVANT de stocker !

**Ordre correct** :
1. Charger ‚Üí 2. D√©couper ‚Üí 3. Vectoriser ‚Üí 4. Stocker ‚Üí 5. Chercher ‚Üí 6. G√©n√©rer

---

**Score Partie 6** : üîÑ **1/2**

---

# üéÅ BONUS - Question de Synth√®se

### Question Bonus (non pos√©e)
Tu dois cr√©er un chatbot qui :
- Se souvient de la conversation
- Peut r√©pondre √† des questions sur un fichier PDF de r√®glement interne

Quels composants de LangChain vas-tu utiliser ? (Cite au moins 5 √©l√©ments)

---

# üèÜ R√âSULTATS FINAUX

## üìä Score par Partie

| Partie | Score | Appr√©ciation |
|--------|-------|--------------|
| 1. M√©taphore | 3/5 | üîÑ √Ä revoir |
| 2. Fondations | 3/3 | ‚úÖ Acquis |
| 3. Prompt Templates | 2/3 | üîÑ Partiel |
| 4. Chains/LCEL | 1/3 | ‚ùå √Ä travailler |
| 5. M√©moire | 3/3 | ‚úÖ Acquis |
| 6. RAG | 1/2 | üîÑ Partiel |
| **TOTAL** | **10/15** | **67%** |

---

## üí™ Points Forts

- ‚úÖ **Fondations** : Ma√Ætrise de LLM, API Key, `invoke()`
- ‚úÖ **M√©moire** : Excellente compr√©hension du stateless, MessagesPlaceholder, session_id
- ‚úÖ **Exemples concrets** : Capacit√© √† illustrer les concepts (mayonnaise, Antoine)

## üìö Points √† R√©viser

| Concept | Ce qu'il faut retenir |
|---------|----------------------|
| **LCEL** | = LangChain Expression Language (syntaxe avec `\|`) |
| **StrOutputParser** | Nettoie la **sortie** du LLM (pas l'entr√©e !) |
| **Ch√¢ssis** | = LangChain (le framework), pas l'API |
| **RAG** | = Retrieval Augmented Generation |
| **Ordre RAG** | Vectoriser **avant** de stocker |
| **Avantages Templates** | R√©utilisabilit√© + Contextualisation |

---

## üéì Verdict Final

> **Bon niveau g√©n√©ral !** Compr√©hension solide des concepts cl√©s et de leurs usages pratiques. Quelques d√©finitions techniques √† m√©moriser (LCEL, RAG) et la Le√ßon 3 (Chains) √† retravailler.

**Recommandation** : Relire la Le√ßon 3 sur les Chains et LCEL.
