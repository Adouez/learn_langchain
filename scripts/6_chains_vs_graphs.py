"""
âš”ï¸ LeÃ§on 7 : Chains vs Graphs - Comparaison Pratique
=====================================================

Ce script montre le MÃŠME problÃ¨me rÃ©solu de deux faÃ§ons :
1. Avec LCEL (Chains) - Approche linÃ©aire
2. Avec LangGraph - Approche avec Ã©tat et conditions

ProblÃ¨me : Un assistant qui analyse le sentiment d'un texte
et donne une rÃ©ponse adaptÃ©e (encouragement ou fÃ©licitations).

Tu verras que :
- LCEL est plus concis pour les flux simples
- LangGraph permet d'ajouter des conditions et boucles
"""

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, START, END
from typing import TypedDict, Literal

load_dotenv()

# Le modÃ¨le utilisÃ© par les deux approches
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”— APPROCHE 1 : LCEL (Chains) - Flux LinÃ©aire
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("=" * 70)
print("ğŸ”— APPROCHE 1 : LCEL (Chains)")
print("=" * 70)

# Avec LCEL, on doit tout faire en une seule chaÃ®ne linÃ©aire
# Le LLM doit analyser ET rÃ©pondre en mÃªme temps

prompt_lcel = ChatPromptTemplate.from_messages([
    ("system", """Tu es un assistant empathique.
Analyse le sentiment du message (positif, nÃ©gatif, neutre).
Puis rÃ©ponds de maniÃ¨re adaptÃ©e :
- Si nÃ©gatif : encourage et rÃ©conforte
- Si positif : fÃ©licite
- Si neutre : rÃ©ponds normalement

Format ta rÃ©ponse ainsi :
SENTIMENT: [positif/nÃ©gatif/neutre]
RÃ‰PONSE: [ta rÃ©ponse adaptÃ©e]"""),
    ("human", "{message}")
])

# La chaÃ®ne : Prompt â†’ LLM â†’ Parser (tout linÃ©aire)
chain_lcel = prompt_lcel | llm | StrOutputParser()

# Test
message_test = "J'ai ratÃ© mon examen et je suis vraiment dÃ©Ã§u..."

print(f"\nğŸ“ Message : \"{message_test}\"\n")
print("â³ Traitement avec LCEL...")
result_lcel = chain_lcel.invoke({"message": message_test})
print(f"ğŸ“¤ RÃ©sultat :\n{result_lcel}")

print("\n" + "-" * 70)
print("ğŸ’¡ LCEL : Simple mais tout est fait en UN appel, pas de logique conditionnelle")
print("-" * 70)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š APPROCHE 2 : LangGraph - Flux avec Ã‰tat et Conditions
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 70)
print("ğŸ“Š APPROCHE 2 : LangGraph (avec conditions)")
print("=" * 70)


# 1. DÃ©finir l'Ã©tat partagÃ© entre les nÅ“uds
class SentimentState(TypedDict):
    message: str           # Le message d'entrÃ©e
    sentiment: str         # Le sentiment dÃ©tectÃ©
    response: str          # La rÃ©ponse gÃ©nÃ©rÃ©e


# 2. NÅ“ud 1 : Analyser le sentiment
def analyze_sentiment(state: SentimentState) -> SentimentState:
    """Analyse le sentiment du message."""
    prompt = ChatPromptTemplate.from_messages([
        ("system", "Analyse le sentiment de ce message. RÃ©ponds UNIQUEMENT par: positif, nÃ©gatif ou neutre"),
        ("human", "{message}")
    ])
    chain = prompt | llm | StrOutputParser()
    sentiment = chain.invoke({"message": state["message"]}).strip().lower()
    print(f"   ğŸ” Sentiment dÃ©tectÃ© : {sentiment}")
    return {"sentiment": sentiment}


# 3. NÅ“uds de rÃ©ponse (un par type de sentiment)
def respond_negative(state: SentimentState) -> SentimentState:
    """RÃ©ponse pour sentiment nÃ©gatif."""
    prompt = ChatPromptTemplate.from_messages([
        ("system", "L'utilisateur est triste ou dÃ©Ã§u. RÃ©conforte-le avec empathie et encouragement."),
        ("human", "{message}")
    ])
    chain = prompt | llm | StrOutputParser()
    response = chain.invoke({"message": state["message"]})
    print(f"   ğŸ’™ Route : rÃ©ponse_nÃ©gative")
    return {"response": response}


def respond_positive(state: SentimentState) -> SentimentState:
    """RÃ©ponse pour sentiment positif."""
    prompt = ChatPromptTemplate.from_messages([
        ("system", "L'utilisateur est content. FÃ©licite-le et partage sa joie !"),
        ("human", "{message}")
    ])
    chain = prompt | llm | StrOutputParser()
    response = chain.invoke({"message": state["message"]})
    print(f"   ğŸ’š Route : rÃ©ponse_positive")
    return {"response": response}


def respond_neutral(state: SentimentState) -> SentimentState:
    """RÃ©ponse pour sentiment neutre."""
    prompt = ChatPromptTemplate.from_messages([
        ("system", "RÃ©ponds de maniÃ¨re informative et neutre."),
        ("human", "{message}")
    ])
    chain = prompt | llm | StrOutputParser()
    response = chain.invoke({"message": state["message"]})
    print(f"   âšª Route : rÃ©ponse_neutre")
    return {"response": response}


# 4. Fonction de routage (dÃ©cide quelle branche prendre)
def route_by_sentiment(state: SentimentState) -> Literal["respond_negative", "respond_positive", "respond_neutral"]:
    """DÃ©cide quel nÅ“ud appeler selon le sentiment."""
    sentiment = state.get("sentiment", "").lower()
    if "nÃ©gatif" in sentiment or "negatif" in sentiment or "negative" in sentiment:
        return "respond_negative"
    elif "positif" in sentiment or "positive" in sentiment:
        return "respond_positive"
    else:
        return "respond_neutral"


# 5. Construire le graphe
graph = StateGraph(SentimentState)

# Ajouter les nÅ“uds
graph.add_node("analyze", analyze_sentiment)
graph.add_node("respond_negative", respond_negative)
graph.add_node("respond_positive", respond_positive)
graph.add_node("respond_neutral", respond_neutral)

# DÃ©finir les connexions
graph.add_edge(START, "analyze")  # DÃ©but â†’ Analyse

# CONDITION : AprÃ¨s l'analyse, on route vers le bon nÅ“ud de rÃ©ponse
graph.add_conditional_edges(
    "analyze",
    route_by_sentiment,
    {
        "respond_negative": "respond_negative",
        "respond_positive": "respond_positive",
        "respond_neutral": "respond_neutral"
    }
)

# Toutes les rÃ©ponses mÃ¨nent Ã  la fin
graph.add_edge("respond_negative", END)
graph.add_edge("respond_positive", END)
graph.add_edge("respond_neutral", END)

# Compiler le graphe
app = graph.compile()


# Test avec le mÃªme message
print(f"\nğŸ“ Message : \"{message_test}\"\n")
print("â³ Traitement avec LangGraph...")
print("   ğŸ“Š Ã‰tapes du graphe :")

result_graph = app.invoke({"message": message_test})
print(f"\nğŸ“¤ RÃ©sultat :\n{result_graph['response']}")

print("\n" + "-" * 70)
print("ğŸ’¡ LangGraph : Plus verbeux mais permet des VRAIES conditions")
print("   Le flux a pris un chemin diffÃ©rent selon le sentiment dÃ©tectÃ© !")
print("-" * 70)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª TEST COMPARATIF : Message Positif
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 70)
print("ğŸ§ª TEST BONUS : Message Positif")
print("=" * 70)

message_positif = "J'ai eu mon diplÃ´me ! Je suis tellement heureux !"
print(f"\nğŸ“ Message : \"{message_positif}\"\n")

print("ğŸ”— LCEL :")
result_lcel_2 = chain_lcel.invoke({"message": message_positif})
print(f"{result_lcel_2}\n")

print("ğŸ“Š LangGraph :")
print("   ğŸ“Š Ã‰tapes du graphe :")
result_graph_2 = app.invoke({"message": message_positif})
print(f"\n{result_graph_2['response']}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“š RÃ‰CAPITULATIF
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 70)
print("ğŸ“š RÃ‰CAPITULATIF")
print("=" * 70)
print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LCEL (Chains)                  â”‚  LangGraph                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  prompt | llm | parser          â”‚  StateGraph + add_node + add_edge â”‚
â”‚  Flux linÃ©aire uniquement       â”‚  Conditions et boucles possibles  â”‚
â”‚  1 appel LLM (tout en un)       â”‚  Plusieurs appels (Ã©tape par      â”‚
â”‚                                 â”‚  Ã©tape)                           â”‚
â”‚  Plus concis                    â”‚  Plus explicite                   â”‚
â”‚  IdÃ©al pour pipelines simples   â”‚  IdÃ©al pour agents/workflows      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ RÃ¨gle d'or : Commence avec LCEL, passe Ã  LangGraph si tu as besoin
   de boucles, conditions, ou d'un contrÃ´le fin sur le flux.
""")
