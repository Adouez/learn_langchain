"""
ğŸ¨ LeÃ§on 8 : Application Chatbot avec Streamlit
===============================================

Une interface graphique complÃ¨te pour ton chatbot LangChain !

Pour lancer : streamlit run scripts/7_app_streamlit.py
"""

import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

load_dotenv()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš™ï¸ CONFIGURATION DE LA PAGE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.set_page_config(
    page_title="Chatbot LangChain",
    page_icon="ğŸ¤–",
    layout="centered",
    initial_sidebar_state="expanded"
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¨ SIDEBAR - PARAMÃˆTRES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

with st.sidebar:
    st.header("âš™ï¸ ParamÃ¨tres")
    
    # SÃ©lection du modÃ¨le
    model_name = st.selectbox(
        "ğŸ§  ModÃ¨le",
        ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"],
        index=0
    )
    
    # Slider pour la tempÃ©rature (crÃ©ativitÃ©)
    temperature = st.slider(
        "ğŸ¨ CrÃ©ativitÃ©",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="0 = RÃ©ponses prÃ©cises, 1 = RÃ©ponses crÃ©atives"
    )
    
    # PersonnalitÃ© du bot
    personality = st.text_area(
        "ğŸ­ PersonnalitÃ© du bot",
        value="Tu es un assistant amical et pÃ©dagogue. Tu expliques les concepts de maniÃ¨re simple avec des exemples concrets.",
        height=100
    )
    
    st.divider()
    
    # Bouton pour effacer la conversation
    if st.button("ğŸ—‘ï¸ Effacer la conversation", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.divider()
    
    # Infos
    st.caption("ğŸ“ Projet Learn LangChain")
    st.caption(f"ğŸ“Š Messages : {len(st.session_state.get('messages', []))}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  INITIALISATION DU MODÃˆLE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# @st.cache_resource permet de ne crÃ©er le LLM qu'une seule fois
# (optimisation importante !)
@st.cache_resource
def get_llm(model: str, temp: float):
    """CrÃ©e et cache l'instance du LLM."""
    return ChatOpenAI(model=model, temperature=temp)


# On recrÃ©e le LLM si les paramÃ¨tres changent
llm = get_llm(model_name, temperature)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ’¾ MÃ‰MOIRE DE SESSION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Initialiser l'historique des messages (une seule fois)
if "messages" not in st.session_state:
    st.session_state.messages = []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¨ INTERFACE PRINCIPALE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Titre
st.title("ğŸ¤– Chatbot LangChain")
st.caption("Ton assistant IA propulsÃ© par LangChain et OpenAI")

# Afficher l'historique des messages
for message in st.session_state.messages:
    role = message["role"]
    content = message["content"]
    
    with st.chat_message(role):
        st.markdown(content)

# Message d'accueil si conversation vide
if not st.session_state.messages:
    with st.chat_message("assistant"):
        st.markdown("ğŸ‘‹ Bonjour ! Je suis ton assistant. Pose-moi une question !")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ’¬ GESTION DU CHAT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Zone de saisie
if prompt := st.chat_input("Tape ton message ici..."):
    
    # 1. Afficher le message de l'utilisateur
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # 2. Sauvegarder dans l'historique
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # 3. PrÃ©parer les messages pour le LLM (avec la personnalitÃ©)
    messages_for_llm = [SystemMessage(content=personality)]
    
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            messages_for_llm.append(HumanMessage(content=msg["content"]))
        else:
            messages_for_llm.append(AIMessage(content=msg["content"]))
    
    # 4. GÃ©nÃ©rer la rÃ©ponse
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤” RÃ©flexion en cours..."):
            response = llm.invoke(messages_for_llm)
            response_content = response.content
        
        # Afficher la rÃ©ponse
        st.markdown(response_content)
    
    # 5. Sauvegarder la rÃ©ponse dans l'historique
    st.session_state.messages.append({"role": "assistant", "content": response_content})


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š FOOTER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.divider()
col1, col2, col3 = st.columns(3)
with col1:
    st.caption(f"ğŸ§  ModÃ¨le : {model_name}")
with col2:
    st.caption(f"ğŸ¨ TempÃ©rature : {temperature}")
with col3:
    st.caption(f"ğŸ’¬ Messages : {len(st.session_state.messages)}")
