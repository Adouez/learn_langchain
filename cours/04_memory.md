# ğŸ§  LeÃ§on 4 : La MÃ©moire (Memory)

## ğŸ“– Introduction

Par dÃ©faut, un LLM est "**stateless**" (sans Ã©tat) : il oublie tout aprÃ¨s chaque rÃ©ponse. 

Pour crÃ©er un vrai Chatbot qui se souvient de la conversation, il faut **injecter l'historique** dans le Prompt Ã  chaque tour.

---

## ğŸ”„ Comment Ã§a marche ?

Au lieu d'envoyer juste la question actuelle, on envoie :

```
[Historique des messages] + [Nouvelle Question]
```

> ğŸ’¡ **MÃ©taphore** : C'est comme un GPS avec historique. Au lieu de demander "OÃ¹ aller ?", tu demandes "En partant de lÃ  oÃ¹ j'Ã©tais, oÃ¹ aller maintenant ?".

---

## ğŸ§© Composants ClÃ©s

### 1. `MessagesPlaceholder`
Une case vide dans le Prompt Template rÃ©servÃ©e pour insÃ©rer l'historique de conversation.

```python
MessagesPlaceholder(variable_name="history")
```

C'est comme rÃ©server une place dans un formulaire pour "coller" l'historique plus tard.

### 2. `RunnableWithMessageHistory`
Un outil qui gÃ¨re automatiquement :
- La sauvegarde des messages (ce que tu dis ET ce que le bot rÃ©pond)
- La rÃ©injection de l'historique au tour suivant

### 3. `session_id`
Un identifiant unique pour distinguer les conversations de diffÃ©rents utilisateurs.

> ğŸ’¡ Alice et Bob peuvent parler au mÃªme bot sans mÃ©langer leurs historiques grÃ¢ce au `session_id`.

---

## ğŸ’» Exemple de Code

**Fichier** : `scripts/3_memory.py`

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory

# 1. Prompt avec emplacement pour l'historique
prompt = ChatPromptTemplate.from_messages([
    ("system", "Tu es un assistant amical."),
    MessagesPlaceholder(variable_name="history"),  # <-- La mÃ©moire
    ("human", "{question}")
])

# 2. Stockage de l'historique (en RAM ici)
store = {}

def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# 3. ChaÃ®ne avec mÃ©moire
chain_with_history = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="question",
    history_messages_key="history"
)

# 4. Utilisation avec session_id
response = chain_with_history.invoke(
    {"question": "Je m'appelle Alice"},
    config={"configurable": {"session_id": "user_123"}}
)
```

---

## ğŸ“Š Flux de la MÃ©moire

```
Tour 1: "Je m'appelle Alice"
        â†“
[history: vide] + "Je m'appelle Alice" â†’ Bot: "Bonjour Alice !"
        â†“
Sauvegarde: [Human: "Je m'appelle Alice", AI: "Bonjour Alice !"]

Tour 2: "Quel est mon nom ?"
        â†“
[history: Human+AI prÃ©cÃ©dents] + "Quel est mon nom ?" â†’ Bot: "Tu es Alice !"
```

---

## âœ… Points Ã  Retenir

- Les LLMs sont **stateless** par dÃ©faut (sans mÃ©moire)
- `MessagesPlaceholder` = L'emplacement rÃ©servÃ© pour l'historique
- `RunnableWithMessageHistory` = Le gestionnaire automatique de mÃ©moire
- `session_id` = Identifiant unique par utilisateur/conversation

---

## ğŸ†• Note : Ã‰volution vers LangGraph (LangChain 1.x)

Depuis **LangChain 1.x**, une nouvelle approche est disponible via **LangGraph** :

| Approche | Outil | Cas d'usage |
|----------|-------|-------------|
| **Classique** | `RunnableWithMessageHistory` | ChaÃ®nes simples, facile Ã  comprendre |
| **Moderne** | LangGraph + `MemorySaver` | Agents, workflows complexes, plus de contrÃ´le |

### Avec LangGraph, la mÃ©moire est gÃ©rÃ©e via un **Ã©tat** :

```python
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import create_react_agent

# Le checkpointer sauvegarde l'Ã©tat (dont les messages)
memory = MemorySaver()

agent = create_react_agent(llm, tools, checkpointer=memory)

# Le thread_id remplace le session_id
config = {"configurable": {"thread_id": "user_123"}}
result = agent.invoke({"messages": [...]}, config=config)
```

> ğŸ’¡ **Conseil** : Commence par `RunnableWithMessageHistory` pour comprendre le concept, puis passe Ã  LangGraph quand tu travailles avec des Agents.

ğŸ“ Voir le script `3bis_memory_langgraph.py` pour un exemple complet.

---

## ğŸ”œ Prochaine LeÃ§on

Notre bot a de la mÃ©moire, mais il ne connaÃ®t que ce qu'il a appris pendant son entraÃ®nement. Comment lui faire lire VOS documents ? C'est le **RAG** !
